{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe3c5033510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "import logging\n",
    "from random import seed\n",
    "import neptune\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from torch import load\n",
    "from random import sample\n",
    "from torchvision import transforms\n",
    "from federated_learning.FLCustomDataset import FLCustomDataset\n",
    "from federated_learning.FederatedLearning import FederatedLearning\n",
    "from federated_learning.helper import utils\n",
    "\n",
    "arguments = dict()\n",
    "arguments['--output-prefix'] = \"\"\n",
    "\n",
    "CONFIG_PATH = '../configs/defaults.yml'\n",
    "\n",
    "configs = utils.load_config(CONFIG_PATH)\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=configs['log']['level'])\n",
    "random_seed = configs['runtime']['random_seed']\n",
    "seed(random_seed)\n",
    "\n",
    "# Logging initialization\n",
    "log_enable = False\n",
    "output_dir = None\n",
    "if log_enable:\n",
    "    output_dir = utils.make_output_dir(\n",
    "        configs['log']['root_output_dir'], arguments['--output-prefix'])\n",
    "    utils.save_configs(output_dir, configs)\n",
    "neptune_enable = False\n",
    "\n",
    "# Neptune logging initialization\n",
    "if neptune_enable:\n",
    "    neptune.init(configs['log']['neptune_init'])\n",
    "    neptune.create_experiment(name = configs['log']['neptune_exp'])\n",
    "\n",
    "# syft initialization\n",
    "hook = sy.TorchHook(torch)\n",
    "use_cuda = False\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_learning.FLNet import FLNet\n",
    "tmp_model = FLNet().to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0603, -0.0477, -0.0789, -0.0583,  0.1467,  0.1109,  0.0871, -0.0192,\n",
      "         0.0964,  0.0262, -0.0770, -0.0780,  0.0882,  0.0009,  0.1538,  0.1351,\n",
      "         0.1136, -0.1533, -0.1837,  0.0886], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "dd = tmp_model.state_dict()\n",
    "for i, j in tmp_model.named_parameters():\n",
    "    print(i)\n",
    "\n",
    "print_model(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0603, -0.0477, -0.0789, -0.0583,  0.1467,  0.1109,  0.0871])\n"
     ]
    }
   ],
   "source": [
    "def print_model(model):\n",
    "    for ii, jj in model.named_parameters():\n",
    "        if ii == \"conv1.bias\":\n",
    "            print(jj.data[:7])\n",
    "            \n",
    "print_model(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5, 5])\n",
      "torch.Size([20, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.tensor([0] * torch.numel(bb)).view(bb.shape)\n",
    "print(aa.shape)\n",
    "# torch.reshape(aa, list(bb.size()))\n",
    "# print(aa.shape)\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "selected_users_num = configs['mnist']['selected_users_num']\n",
    "for round_no in range(rounds_num):\n",
    "    # select selected_users_num users randomly\n",
    "    workers_to_be_used = sample(workers_idx, selected_users_num)\n",
    "    logging.info(\"Selected users for this round: {}\".format(workers_to_be_used))\n",
    "\n",
    "    logging.info(\"Create workers model for this round based on the server model...\")\n",
    "    workers_model = dict()\n",
    "    for worker_id in workers_to_be_used:\n",
    "        workers_model[worker_id] = deepcopy(fl.server_model)\n",
    "\n",
    "    fl.train_workers(fed_train_dataloaders, workers_model, round_no, epochs_num)\n",
    "\n",
    "    # Find the best weights and update the server model\n",
    "    weights = None\n",
    "    if arguments['--avg']:\n",
    "        # Each worker takes two shards of 300 samples. Total of 600 samples\n",
    "        # per worker. Total number of samples is 60000.\n",
    "        weights = [600.0 / 60000] * selected_users_num\n",
    "    # elif arguments['--opt']:\n",
    "    #     # weights = fl.find_best_weights(trained_server_model, workers_idx)\n",
    "    #     weights = fl.find_best_weights(trained_w0_model, workers_idx)\n",
    "\n",
    "    if log_enable:\n",
    "        fl.save_workers_model(workers_idx, str(round_no))\n",
    "        # fl.save_model(\n",
    "        #     fl.get_average_model(trusted_idx),\n",
    "        #     \"R{}_{}\".format(round_no, \"avg_trusted_model\")\n",
    "        # )\n",
    "\n",
    "    logging.info(\"Update server model in this round...\")\n",
    "    fl.update_models([\"server\"], fl.wieghted_avg_model(weights, workers_idx))\n",
    "\n",
    "    # Apply the server model to the test dataset\n",
    "    fl.test(fl.server_model, test_dataloader, round_no)\n",
    "\n",
    "    if log_enable:\n",
    "        fl.save_model(\n",
    "            fl.server_model, \n",
    "            \"R{}_{}\".format(round_no, \"server_model\")\n",
    "        )\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
