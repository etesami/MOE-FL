{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/ubuntu/.local/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 19:14:14,156 Initializing Federated Learning class...\n",
      "2020-12-02 19:14:14,920 Creating the server...\n",
      "2020-12-02 19:14:14,922 Creating a model for the server...\n",
      "2020-12-02 19:14:14,931 Creating workers...\n",
      "2020-12-02 19:14:14,934 Creating a model for 30 worker(s)...\n",
      "2020-12-02 19:14:15,094 Eavesdroppers: ['worker_13', 'worker_23', 'worker_0', 'worker_26', 'worker_25']\n",
      "2020-12-02 19:14:15,095 Normal: ['worker_9', 'worker_27', 'worker_11', 'worker_29', 'worker_6', 'worker_8', 'worker_18', 'worker_5', 'worker_3', 'worker_17', 'worker_20', 'worker_19', 'worker_2', 'worker_16', 'worker_4', 'worker_10', 'worker_14', 'worker_22', 'worker_21', 'worker_24', 'worker_28', 'worker_12', 'worker_7', 'worker_1', 'worker_15']\n",
      "2020-12-02 19:14:15,097 Loading 30% of train data from MNIST dataset.\n",
      "2020-12-02 19:14:15,234 Preparing the MNIST dataset.\n",
      "2020-12-02 19:14:15,266 Creating MNIST dataset.\n",
      "2020-12-02 19:14:15,321 Loading test data from MNIST dataset.\n",
      "2020-12-02 19:14:15,343 Creating MNIST dataset.\n",
      "2020-12-02 19:14:15,374 Creating data loader.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import neptune\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from torch import load\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from federated_learning.FLCustomDataset import FLCustomDataset\n",
    "from federated_learning.FederatedLearning import FederatedLearning\n",
    "from federated_learning.helper import utils\n",
    "\n",
    "CONFIG_PATH = '../configs/defaults.yml'\n",
    "configs = utils.load_config(CONFIG_PATH)\n",
    "arguments = dict()\n",
    "arguments['--reg'] = 0.0\n",
    "arguments['--output-prefix'] = \"mnist_no_attack\"\n",
    "arguments['--server_model'] = \"data_output/20201107_030649_mnist_w0/server_model_9\"\n",
    "arguments[\"--epoch\"] = 1\n",
    "arguments[\"--round\"] = 1\n",
    "output_dir = None\n",
    "log_enable = False\n",
    "neptune_enable = False\n",
    "\n",
    "\n",
    "configs = utils.load_config(CONFIG_PATH)\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=configs['log']['level'])\n",
    "random.seed(configs['runtime']['random_seed'])\n",
    "\n",
    "# From command line\n",
    "epochs_num = int(arguments[\"--epoch\"])\n",
    "rounds_num = int(arguments[\"--round\"])\n",
    "\n",
    "\n",
    "fl = FederatedLearning(\n",
    "    configs['runtime']['batch_size'], \n",
    "    configs['runtime']['test_batch_size'], \n",
    "    configs['runtime']['lr'], \n",
    "    float(arguments['--reg']) if arguments['--reg'] is not None else 0.0,\n",
    "    configs['runtime']['momentum'], \n",
    "    neptune_enable, log_enable, \n",
    "    configs['log']['interval'], \n",
    "    output_dir, \n",
    "    configs['runtime']['random_seed'])\n",
    "\n",
    "\n",
    "fl.create_server()\n",
    "fl.create_server_model()\n",
    "\n",
    "total_num_workers = \\\n",
    "        configs['runtime']['mnist_normal_users_num'] + \\\n",
    "        configs['runtime']['mnist_eavesdropper_num'] \n",
    "        # configs['runtime']['mnist_trusted_users_num']\n",
    "\n",
    "workers_idx = [\"worker_\" + str(i) for i in range(total_num_workers)]\n",
    "fl.create_workers(workers_idx)\n",
    "fl.create_workers_model(workers_idx)\n",
    "\n",
    "# trusted_idx = utils.get_workers_idx(\n",
    "#     range(total_num_workers), configs['runtime']['mnist_trusted_users_num'], [])\n",
    "eavesdroppers_idx = utils.get_workers_idx(\n",
    "    range(total_num_workers), configs['runtime']['mnist_eavesdropper_num'], [])\n",
    "normal_idx = utils.get_workers_idx(\n",
    "    range(total_num_workers), configs['runtime']['mnist_normal_users_num'], eavesdroppers_idx)\n",
    "\n",
    "# trusted_idx = [workers_idx[ii] for ii in trusted_idx]\n",
    "eavesdroppers_idx = [workers_idx[ii] for ii in eavesdroppers_idx]\n",
    "normal_idx = [workers_idx[ii] for ii in normal_idx]\n",
    "\n",
    "# logging.info(\"Trusted: {}\".format(trusted_idx))\n",
    "logging.info(\"Eavesdroppers: {}\".format(eavesdroppers_idx))\n",
    "logging.info(\"Normal: {}\".format(normal_idx))\n",
    "if log_enable:\n",
    "    # utils.write_to_file(output_dir, \"trusted\", trusted_idx)\n",
    "    utils.write_to_file(output_dir, \"eavesdroppers\", eavesdroppers_idx)\n",
    "    utils.write_to_file(output_dir, \"normal\", normal_idx)\n",
    "\n",
    "train_raw_dataset = utils.preprocess_mnist(\n",
    "    utils.load_mnist_data_train(\n",
    "        configs['data']['MNIST_PATH'], \n",
    "        configs['runtime']['mnist_data_percentage']))\n",
    "train_dataset = utils.get_mnist_dataset(train_raw_dataset)\n",
    "\n",
    "test_data = utils.load_mnist_data_test(configs['data']['MNIST_PATH'])\n",
    "test_dataset = utils.get_mnist_dataset(test_data)\n",
    "test_dataloader = utils.get_dataloader(\n",
    "    test_dataset, configs['runtime']['test_batch_size'], shuffle=True, drop_last=False)\n",
    "\n",
    "# W0 model\n",
    "trained_w0_model = load(configs['runtime']['W0_pure_path'])\n",
    "\n",
    "federated_train_dataloader = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 19:14:16,335 (500, 30)\n",
      "2020-12-02 19:14:16,336 (20, 30)\n",
      "2020-12-02 19:14:16,355 (25000, 30)\n",
      "2020-12-02 19:14:16,357 (50, 30)\n",
      "2020-12-02 19:14:17,190 (400000, 30)\n",
      "2020-12-02 19:14:17,193 (500, 30)\n",
      "2020-12-02 19:14:17,199 (5000, 30)\n",
      "2020-12-02 19:14:17,200 (10, 30)\n",
      "2020-12-02 19:14:17,798 [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.  1. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "2020-12-02 19:14:17,801 \n"
     ]
    }
   ],
   "source": [
    "ww = fl.find_best_weights(trained_w0_model, workers_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,  1.,\n",
       "       -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "       -0., -0., -0., -0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
