{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/ubuntu/.local/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from docopt import docopt\n",
    "import logging\n",
    "import neptune\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from torch import load\n",
    "from random import seed, sample\n",
    "from torch import optim, float32, int64, tensor\n",
    "from torchvision import transforms\n",
    "from federated_learning.FLCustomDataset import FLCustomDataset\n",
    "from federated_learning.FederatedLearning import FederatedLearning\n",
    "from federated_learning.helper import utils\n",
    "CONFIG_PATH = '../configs/defaults.yml'\n",
    "\n",
    "configs = utils.load_config(CONFIG_PATH)\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=configs['log']['level'])\n",
    "seed(configs['runtime']['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 21:52:44,852 Initializing Federated Learning class...\n",
      "2020-12-10 21:52:45,616 Creating the server...\n",
      "2020-12-10 21:52:45,617 Creating a model for the server...\n",
      "2020-12-10 21:52:45,627 Loading train dataset from /home/ubuntu/data/leaf_non_iid/data/femnist/data\n",
      "2020-12-10 21:52:45,629 Loading 1 out of 2 files...\n",
      "2020-12-10 21:52:51,125 Loading 2 out of 2 files...\n",
      "2020-12-10 21:52:56,123 Start processing of femnist data...\n",
      "2020-12-10 21:52:57,788 Loading test dataset from /home/ubuntu/data/leaf_non_iid/data/femnist/data\n",
      "2020-12-10 21:52:57,798 Loading 1 out of 2 files...\n",
      "2020-12-10 21:52:58,242 Loading 2 out of 2 files...\n",
      "2020-12-10 21:52:58,687 Start processing of femnist data...\n",
      "2020-12-10 21:52:58,778 Creating workers...\n",
      "2020-12-10 21:52:58,787 Creating a model for 100 worker(s)...\n",
      "2020-12-10 21:52:59,192 Eavesdroppers: ['f0826_18', 'f0735_17', 'f0680_28', 'f0647_19', 'f0956_32']\n",
      "2020-12-10 21:52:59,193 Normal: ['f0530_15', 'f0877_17', 'f0987_34', 'f0654_02', 'f0750_18', 'f0673_28', 'f0612_11', 'f0792_07', 'f0794_31', 'f0620_49', 'f0532_09', 'f0951_29', 'f0770_45', 'f0703_11', 'f0931_37', 'f0609_12', 'f0734_39', 'f0640_19', 'f0766_01', 'f0625_26', 'f0743_31', 'f0644_19', 'f0738_13', 'f0876_43', 'f0962_04', 'f0986_02', 'f0984_25', 'f0961_08', 'f0558_01', 'f0521_14', 'f0940_45', 'f0818_03', 'f0554_17', 'f0809_16', 'f0947_41', 'f0681_47', 'f0924_33', 'f0635_33', 'f0547_28', 'f0870_31', 'f0863_41', 'f0804_00', 'f0910_22', 'f0868_03', 'f0991_47', 'f0510_47', 'f0839_37', 'f0509_28', 'f0616_04', 'f0561_12', 'f0763_30', 'f0747_24', 'f0631_03', 'f0721_31', 'f0988_45', 'f0568_00', 'f0943_40', 'f0762_20', 'f0722_29', 'f0629_39', 'f0945_28', 'f0570_31', 'f0919_47', 'f0789_10', 'f0834_03', 'f0527_23', 'f0933_38', 'f0859_01', 'f0726_09', 'f0528_49', 'f0758_07', 'f0630_16', 'f0891_44', 'f0617_30', 'f0573_31', 'f0922_02', 'f0935_28', 'f0759_41', 'f0622_25', 'f0831_15', 'f0676_08', 'f0803_40', 'f0824_18', 'f0590_06', 'f0996_01', 'f0593_46', 'f0833_32', 'f0974_14', 'f0903_42', 'f0524_04', 'f0606_11', 'f0666_20', 'f0857_21', 'f0550_24', 'f0512_15']\n"
     ]
    }
   ],
   "source": [
    "# Logging initialization\n",
    "log_enable = False\n",
    "output_dir = None\n",
    "neptune_enable = False\n",
    "\n",
    "epochs_num = configs['runtime']['epochs']\n",
    "rounds_num = configs['runtime']['rounds']\n",
    "\n",
    "fl = FederatedLearning(\n",
    "    configs['runtime']['batch_size'], \n",
    "    configs['runtime']['test_batch_size'], \n",
    "    configs['runtime']['lr'], \n",
    "    configs['runtime']['reg'],\n",
    "    configs['runtime']['momentum'], \n",
    "    neptune_enable, log_enable, \n",
    "    configs['log']['interval'], \n",
    "    output_dir, \n",
    "    configs['runtime']['random_seed'])\n",
    "\n",
    "fl.create_server()\n",
    "fl.create_server_model()\n",
    "\n",
    "\n",
    "raw_train_data = utils.preprocess_leaf_data(\n",
    "    utils.load_leaf_train(configs['data']['FEMNIST_PATH'])\n",
    ")\n",
    "raw_test_data = utils.preprocess_leaf_data(\n",
    "    utils.load_leaf_test(configs['data']['FEMNIST_PATH']), min_num_samples=configs['runtime']['batch_size']\n",
    ")\n",
    "\n",
    "\n",
    "workers_idx = list(raw_train_data.keys())\n",
    "total_num_workers = len(workers_idx)\n",
    "\n",
    "fl.create_workers(workers_idx)\n",
    "fl.create_workers_model(workers_idx)\n",
    "\n",
    "# trusted_idx = utils.get_workers_idx(\n",
    "#     range(total_num_workers), configs['runtime']['mnist_trusted_users_num'], [])\n",
    "eavesdroppers_idx = utils.get_workers_idx(\n",
    "    workers_idx, configs['runtime']['femnist_eavesdropper_num'], [])\n",
    "normal_idx = utils.get_workers_idx(\n",
    "    workers_idx, \n",
    "    total_num_workers - int(configs['runtime']['femnist_eavesdropper_num']),\n",
    "    eavesdroppers_idx)\n",
    "\n",
    "# logging.info(\"Trusted: {}\".format(trusted_idx))\n",
    "logging.info(\"Eavesdroppers: {}\".format(eavesdroppers_idx))\n",
    "logging.info(\"Normal: {}\".format(normal_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 21:52:59,203 Creating femnist test dataloader possibly for the server\n",
      "2020-12-10 21:52:59,255 Length of Federated Dataset (Total number of records for all workers): 427\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = fl.create_femnist_server_test_dataloader(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "1: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "2: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "3: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "4: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "5: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "6: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "7: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "8: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "9: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "10: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "11: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "12: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "13: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "14: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "15: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "16: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "17: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "18: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "19: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "20: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "21: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "22: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "23: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "24: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "25: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "26: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "27: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "28: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "29: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "30: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "31: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "32: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "33: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "34: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "35: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "36: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "37: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "38: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "39: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "40: torch.Size([10, 1, 28, 28]), torch.Size([10])\n",
      "41: torch.Size([10, 1, 28, 28]), torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for n, (a, b) in enumerate(test_dataloader):\n",
    "    print(\"{}: {}, {}\".format(n, a.get().shape, b.get().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:\t9\n",
      "16:\t6\n",
      "17:\t5\n",
      "18:\t3\n",
      "19:\t3\n",
      "Mean num of samples/user: 17.0\n",
      "Total Samples:\t427\n",
      "Total Users:\t26\n",
      "[f0629_39]: Images: 15, Pixels: 28\n",
      "mean: 0.9637609124183655\n",
      "std: 0.1602856069803238,\n",
      "max: 1.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "utils.dataset_info(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data_x, flattened_data_y = utils.get_flattened_data(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data = utils.preprocess_leaf_data(\n",
    "    utils.load_leaf_test(configs['data']['FEMNIST_PATH']), min_num_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_samples(data):\n",
    "    list_keys = list(data.keys())\n",
    "    data_np = dict()\n",
    "    data_np['x'] = np.array(data[list_keys[0]]['x'], dtype = np.float32).reshape(-1, 28, 28)\n",
    "    data_np['y'] = np.array(data[list_keys[0]]['y'], dtype = np.int64).reshape(-1, 1)\n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "    for i in range(36):\n",
    "        plt.subplot(6, 6, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(data_np['y'][i])\n",
    "        plt.imshow(data_np['x'][i], cmap='gray')\n",
    "        \n",
    "draw_samples(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = utils.preprocess_leaf_data(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.dataset_info(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
